{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMyVG4HSVAHA8Dj/mKdHfzJ"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iHrO3yXdfh6l"
      },
      "outputs": [],
      "source": [
        "WORLD = 1\n",
        "STAGE = 1 \n",
        "LEVEL = f\"{WORLD}-{STAGE}\"\n",
        "QUALITY = 0 \n",
        "DEFAULT_GAME = f\"SuperMarioBros-{LEVEL}-v{QUALITY}\"\n",
        "MY_ACTIONS = [[\"right\"], [\"right\", \"A\"]]\n",
        "batches = 10\n",
        "each_batch_steps = 500000"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q stable-baselines3[extra] > /dev/null 2>&1\n",
        "!pip install -q gym-super-mario-bros > /dev/null 2>&1\n",
        "!pip install -q gym pyvirtualdisplay > /dev/null 2>&1\n",
        "!apt-get install -q -y xvfb python-opengl ffmpeg > /dev/null 2>&1\n",
        "!pip install git+https://github.com/tensorflow/docs > /dev/null 2>&1"
      ],
      "metadata": {
        "id": "tc3YSqhmfnjM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.system(\"Xvfb :1 -screen 0 256x140x24 &\")\n",
        "os.environ['DISPLAY'] = ':1'\n",
        "from IPython import display as ipythondisplay\n",
        "from PIL import Image\n",
        "from pyvirtualdisplay import Display\n",
        "import base64\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_docs.vis.embed as embed\n",
        "import numpy as np\n",
        "import torch\n",
        "import gym\n",
        "from gym.spaces import Box\n",
        "import gym_super_mario_bros\n",
        "from gym.wrappers import FrameStack\n",
        "from nes_py.wrappers import JoypadSpace\n",
        "from gym.wrappers import FrameStack\n",
        "from torchvision import transforms\n",
        "from stable_baselines3 import PPO"
      ],
      "metadata": {
        "id": "OFrVrA1Vfo-6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SkipFrame(gym.Wrapper):\n",
        "    def __init__(self, env, skip):\n",
        "        super().__init__(env)\n",
        "        self._skip = skip\n",
        "\n",
        "    def step(self, action):\n",
        "        total_reward = 0.0\n",
        "        done = False\n",
        "        for i in range(self._skip):\n",
        "            obs, reward, done, info = self.env.step(action)\n",
        "            total_reward += reward\n",
        "            if done:\n",
        "                break\n",
        "        return obs, total_reward, done, info\n",
        "\n",
        "\n",
        "class GrayScaleObservation(gym.ObservationWrapper):\n",
        "    def __init__(self, env):\n",
        "        super().__init__(env)\n",
        "        obs_shape = self.observation_space.shape[:2]\n",
        "        self.observation_space = Box(low=0, high=255, shape=obs_shape, dtype=np.uint8)\n",
        "\n",
        "    def permute_orientation(self, observation):\n",
        "        observation = np.transpose(observation, (2, 0, 1))\n",
        "        observation = torch.tensor(observation.copy(), dtype=torch.float)\n",
        "        return observation\n",
        "\n",
        "    def observation(self, observation):\n",
        "        observation = self.permute_orientation(observation)\n",
        "        transform = transforms.Grayscale()\n",
        "        observation = transform(observation)\n",
        "        return observation\n",
        "\n",
        "\n",
        "class ResizeObservation(gym.ObservationWrapper):\n",
        "    def __init__(self, env, shape):\n",
        "        super().__init__(env)\n",
        "        if isinstance(shape, int):\n",
        "            self.shape = (shape, shape)\n",
        "        else:\n",
        "            self.shape = tuple(shape)\n",
        "\n",
        "        obs_shape = self.shape + self.observation_space.shape[2:]\n",
        "        self.observation_space = Box(low=0, high=255, shape=obs_shape, dtype=np.uint8)\n",
        "\n",
        "    def observation(self, observation):\n",
        "        my_transforms = transforms.Compose(\n",
        "            [transforms.Resize(self.shape), transforms.Normalize(0, 255)]\n",
        "        )\n",
        "        observation = my_transforms(observation).squeeze(0)\n",
        "        return observation\n",
        "\n",
        "def build_env():\n",
        "  env = gym_super_mario_bros.make(DEFAULT_GAME)\n",
        "  env = SkipFrame(env, skip=4)\n",
        "  env = GrayScaleObservation(env)\n",
        "  env = ResizeObservation(env, shape=84)\n",
        "  env = FrameStack(env, num_stack=4)\n",
        "  env = JoypadSpace(env, MY_ACTIONS)\n",
        "  return env"
      ],
      "metadata": {
        "id": "pjvAD7a4fqeU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display = Display(visible=0, size=(400, 300))\n",
        "display.start()\n",
        "\n",
        "\n",
        "def save_gif(model, image_file, max_steps=2000):\n",
        "  best_img = []\n",
        "  all_rewards = []\n",
        "  best_reward = 0\n",
        "  for i in range(20):\n",
        "    env = build_env()\n",
        "    screen = env.render(mode='rgb_array')\n",
        "    im = Image.fromarray(screen)\n",
        "    images = [im]\n",
        "    obs = env.reset()\n",
        "    cur_best_reward = 0\n",
        "    for i in range(1, max_steps + 1):\n",
        "      b = torch.Tensor(4, 84, 84)\n",
        "      torch.stack(obs._frames, out=b)\n",
        "      action, _ = model.predict(b.numpy())\n",
        "\n",
        "      obs, reward, done, _ = env.step(action.tolist())\n",
        "      cur_best_reward += reward\n",
        "\n",
        "      if i % 2 == 0:\n",
        "        screen = env.render(mode='rgb_array')\n",
        "        images.append(Image.fromarray(screen))\n",
        "      if done:\n",
        "        break\n",
        "    all_rewards.append(cur_best_reward)\n",
        "    if cur_best_reward > best_reward or (\n",
        "        cur_best_reward == best_reward and len(images) > len(best_img)\n",
        "    ):\n",
        "      best_reward = cur_best_reward\n",
        "      best_img = images\n",
        "  best_img[0].save(\n",
        "      image_file, save_all=True, append_images=best_img[1:], loop=0, duration=1)"
      ],
      "metadata": {
        "id": "gA6l49cSfunr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prefix = \"ppo_cnn_\"\n",
        "!mkdir -p \"/content/mario_rl/models\"\n",
        "!mkdir -p \"/content/mario_rl/videos\"\n",
        "\n",
        "model = PPO('CnnPolicy', build_env(), verbose=0)\n",
        "\n",
        "base_steps = 0 \n",
        "total_steps = base_steps\n",
        "for i in range(1, 1 + batches):\n",
        "  obs = model.env.reset()\n",
        "  model.learn(total_timesteps=each_batch_steps)\n",
        "  total_steps += each_batch_steps\n",
        "  if each_batch_steps > 50000: \n",
        "    model.save(f\"/content/mario_rl/models/model_{total_steps}\")\n",
        "  save_gif(model, f\"/content/mario_rl/videos/model_{total_steps}.gif\")"
      ],
      "metadata": {
        "id": "m2Oy-O-Dr3eA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed.embed_file(f\"/content/mario_rl/videos/model_{total_steps}.gif\")"
      ],
      "metadata": {
        "id": "MUZLuTSbf0g-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WR6OekEU2bYb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}